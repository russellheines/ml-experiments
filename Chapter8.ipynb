{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZwTir7TEVkJnWV35q4Cz2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/russellheines/ml-experiments/blob/main/Chapter8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.2 Downloading and parsing the initial text file"
      ],
      "metadata": {
        "id": "ByJHTFjIZEcJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca7Y_S4DZA34",
        "outputId": "f835d65d-aecd-4f47-ecab-9adc85858de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus length: 600893\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "path = keras.utils.get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "text = open(path).read().lower()\n",
        "print('Corpus length:', len(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.3 Vectorizing sequences of characters"
      ],
      "metadata": {
        "id": "mUPJMf_CaDJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 60\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen])\n",
        "\n",
        "print('Number of sequences:', len(sentences))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('Unique characteres:', len(chars))\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indices[char]] = 1\n",
        "  y[i, char_indices[next_chars[i]]] = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t80eDWJoZh-C",
        "outputId": "6e11d65a-9c02-481f-d34f-562534190794"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sequences: 200278\n",
            "Unique characteres: 57\n",
            "Vectorization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-ca748dc5ccd1>:17: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
            "<ipython-input-3-ca748dc5ccd1>:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.4 Single-later LSTM model for next-character prediction"
      ],
      "metadata": {
        "id": "EjQSfp72bXS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))"
      ],
      "metadata": {
        "id": "3hBX7_jdaGCT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.5 Model compilation configuration"
      ],
      "metadata": {
        "id": "8VtS3tXjbzFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL4gVKc5bvEs",
        "outputId": "42160511-a241-48dc-a035-0415f68a4b96"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.6 Function to sample the next character given the model's predictions"
      ],
      "metadata": {
        "id": "Ap6T4rEFLPxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "metadata": {
        "id": "tJI101DNb7Ds"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.7 Text generation loop"
      ],
      "metadata": {
        "id": "E3upLGnyL4N-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=128, epochs=1)"
      ],
      "metadata": {
        "id": "IIk_1rDbPk3a",
        "outputId": "aabe47ab-be36-4b33-d93f-1209c6cdeb7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1565/1565 [==============================] - 298s 190ms/step - loss: 2.1436\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fab6dd5b850>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "generated_text = text[start_index: start_index + maxlen]\n",
        "print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "  print('------ temperature:', temperature)\n",
        "  sys.stdout.write(generated_text)\n",
        "\n",
        "  for i in range(400):\n",
        "    sampled = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(generated_text):\n",
        "      sampled[0, t, char_indices[char]] = 1\n",
        "\n",
        "    preds = model.predict(sampled, verbose=0)[0]\n",
        "    next_index = sample(preds, temperature)\n",
        "    next_char = chars[next_index]\n",
        "\n",
        "    generated_text += next_char\n",
        "    generated_text = generated_text[1:]\n",
        "\n",
        "    sys.stdout.write(next_char)\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtbR-C40L1yB",
        "outputId": "bbf4e1f3-49e4-460f-b716-3ceab72df221"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating with seed: \"aordinary furtherers of humanity whom one\n",
            "calls philosophers\"\n",
            "------ temperature: 0.2\n",
            "aordinary furtherers of humanity whom one\n",
            "calls philosophers and the sence to the fore to the fore the senter and the sond as in the sond the reat the sented and it the man the reall the sond the mange and and and and the fore the one the sond the mant and the recente songer soment of the more the songer the senter and condente the of the resting the mere the senter and the of and the expreation and and conders and and and the fored and and mong the sented\n",
            "------ temperature: 0.5\n",
            "nd and conders and and and the fored and and mong the sented the wist be and the ghe preceland, in the sences in the soull gould of in the in the goress in the meall at the mations be us of the bead for to thes meding and best of one of the fors in the have fore tree wern cous the resen at mere has in the menting, and mencing the man the mane and the gorde systong and cevion of the concous and compoun of the forestoly to the sore hit more of the centerst i\n",
            "------ temperature: 1.0\n",
            "poun of the forestoly to the sore hit more of the centerst infeliluass stinl-\n",
            "inconcatis. whald, a.\n",
            "hermens. amminges the lever and of\n",
            "mavin sowe douchy\n",
            "e 1fouch susveseang,y of\n",
            "hemuvts:er amust and ofds. and lowhe stictone thein eephing clacmict hard\n",
            "daculy, whest the inveres allly anliat, ingeysougs only mariol  he veitiand han sungrays\n",
            "sport of it podant, a ho dobesc, the whem as\n",
            "micari, ove fof\n",
            "s the keqtist foow han the poicantsy nove sanken of e belf\n",
            "------ temperature: 1.2\n",
            "f\n",
            "s the keqtist foow han the poicantsy nove sanken of e belf guron\n",
            "sigich wheces not cesimfpunac, fiomi pa acty? in ihmselund in fxsachad of dhersiat of mincel, ate for\n",
            "fultes to sm mimpruity, mate ouls ntheres. s hedicntcal in\n",
            "toist\n",
            " f thuif foce sof\n",
            "al whit tore went\n",
            "wo dtakigisy of s of thonoth of whof \"te wol. the\n",
            "=primum nce oh\n",
            "is stiat of mamewe oulf of bypessirg, ssoisol comathe ta isthingaris spritice of thougchof,, thek\" waolfer sod\n",
            "aby greas styl\n"
          ]
        }
      ]
    }
  ]
}